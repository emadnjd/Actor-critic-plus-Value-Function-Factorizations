üß† Project Title
Exploring Value Function Factorization Methods in Deep Multi-Agent COMA Algorithm

üìÑ Overview
This repository contains the implementation and evaluation of a novel exploration into combining value function factorization methods with the Counterfactual Multi-Agent (COMA) algorithm within deep multi-agent reinforcement learning (MARL).
The project investigates how integrating VDN, QMIX, and a non-monotonic factorization method into the COMA framework influences performance, coordination, and learning efficiency in cooperative multi-agent environments.

üéØ Objectives
Integrate VDN, QMIX, and a non-monotonic method with COMA to enhance credit assignment and coordination.

Evaluate and compare these hybrid approaches against standard COMA in two distinct environments.

Analyze the impact of factorization on policy learning and value estimation within actor-critic MARL settings.

üß™ Environments
The code supports two distinct evaluation environments:

Matrix Game (a discrete, static coordination game)

Predator-Prey Game (a dynamic grid-based cooperative environment)

Each algorithm (COMA and its hybrid variants) was tested in both environments under consistent training conditions for fair and reproducible comparisons.

‚öôÔ∏è Implemented Algorithms:
Baseline: Standard COMA

Hybrid Variants:

VDN-COMA

QMIX-COMA

Non-monotonic-COMA

These variants maintain COMA‚Äôs actor-critic architecture while altering the centralized critic‚Äôs value decomposition strategy.

üìà Evaluation Strategy
To ensure fair comparisons:

All models were trained under identical conditions across both environments.

Key performance metrics (e.g., average episode reward, policy stability) were collected and compared.

The standard COMA implementation serves as the baseline reference.

üßÆ Hyperparameters
The hyperparameters used for training are consistent across algorithms to isolate the impact of the factorization method.

Actor Learning rate (lr_a)

Critic Learning rate (lr_c)

Discount factor (gamma) 

Batch size 

Exploration: epsilon-greedy with decay 

Replay buffer size

Target network update rate

total_timesteps

üèóÔ∏è Repository Structure

coma_matrixgame.py  #  Standard COMA baseline in the matrix game

coma_matrixgame_nonmonotonic.py  #  Non-monotonic plus coma hybrid in the matrix game

coma_matrixgame_qmix.py  #  qmix plus coma hybrid in the matrix game

coma_matrixgame_vdn.py  #  vdn plus coma hybrid in the matrix game

coma_predatorprey.py  #  Standard COMA baseline in the predator prey game

coma_predatorprey_nonmonotonic.py  #  Non-monotonic plus coma hybrid in the predator prey game

coma_predatorprey_qmix.py  #  qmix plus coma hybrid in the predator prey game

coma_predatorprey_vdn.py  #  vdn plus coma hybrid in the predator prey game



